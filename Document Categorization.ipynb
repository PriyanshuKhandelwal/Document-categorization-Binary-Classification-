{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document categorization (Binary Classification):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be using document sets of two different categories and will try to classify them based on the content they hold. We will be using both `Naive Bayes`, `Support Vector Machines` and `Random Forest` algorithm for this classification.\n",
    "\n",
    "Here we will be using document set of **Hockey** and **Baseball** based article set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "hockey_dir = \"Data/data_set/mini_newsgroups/mini_newsgroups/rec.sport.hockey\"\n",
    "baseball_dir = \"Data/data_set/mini_newsgroups/mini_newsgroups/rec.sport.baseball\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['52550',\n",
       " '52555',\n",
       " '52561',\n",
       " '52569',\n",
       " '52587',\n",
       " '52589',\n",
       " '52599',\n",
       " '52600',\n",
       " '52616',\n",
       " '52618']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating corpus\n",
    "# chanding encoding type from 'utf-8' to 'latin-1', as we are getting encoding issues below\n",
    "hockey_corpus = PlaintextCorpusReader(hockey_dir,'.*', encoding='latin-1')\n",
    "baseball_corpus = PlaintextCorpusReader(baseball_dir,'.*',encoding='latin-1')\n",
    "hockey_corpus.fileids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['102590',\n",
       " '102605',\n",
       " '102606',\n",
       " '102612',\n",
       " '102622',\n",
       " '102625',\n",
       " '102631',\n",
       " '102641',\n",
       " '102649',\n",
       " '102655']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_corpus.fileids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newsgroups: rec.sport.hockey\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!usc!cs.utexas.edu!utnut!torn!watserv2.uwaterloo.ca!watmath!undergrad.math.uwaterloo.ca!leibniz.uwaterloo.ca!ayim\\nFrom: ayim@leibniz.uwaterloo.ca (Alfred Yim)\\nSubject: And... THEY\\'RE OFF!!!!!\\nMessage-ID: <C4z808.2v2@undergrad.math.uwaterloo.ca>\\nKeywords: Leafs Chicago\\nSender: news@undergrad.math.uwaterloo.ca\\nOrganization: University of Waterloo\\nDate: Sun, 4 Apr 1993 20:38:32 GMT\\nLines: 39\\n\\nWell, I gotta tell ya,\\n\\nlast night\\'s Leafs game vs the Devils was a nail-bitter LET ME TELL YOU!\\nIt was a well played game by BOTH teams (I thought) but according to the\\nDon and Ron it was the an \"off-night\" for the Leafs and the Devils \\nwere outplaying Toronto. Well, I BEG to differ....\\n\\nIMHO, Clark deserved to be a first star as much as Gilmour did. His\\nfast breaks towards the net and the good opportunites that he\\ncreated reminded me of the Clark of old. (But not to take any of the\\ncredit away from Gilmour).\\n\\nI think the Leafs are playing GREAT hockey. WHY? \\nWell first look at their injury list which includes, Cullen, Ellet,\\nZezel, Macoun. Of course my question is this....how will the Leafs\\nfare when they are once again \"healthy\" if they are playing this well\\nso far??\\n\\nSecond, just look at their standings, still second in defence,\\nmoved from 11th overall to 6th over in the last month, haven\\'t lost\\nat home in last 12 games, 8 game undefeated streak..etc.\\n(BTW, am I wrong or was this Potvin\\'s first shut-out? I can\\'t \\nremember him having any as of yet.)\\n\\nWell, as of April 3 we see that the race for first in the Norris\\nhas truly begun and it will be a VERY CLOSE race between Chicago and\\nToronto. And the best game of the season will probably be their last\\nagainst each other. (is anyone lucky enough to have tickets to\\nsee this one?)\\n\\nComing to the stretch and still a ROAR\\'IN!!!!!\\nGo LEAFS Go!!!!\\n-- \\n****************************************** \\n*  Alfred (Yong-Jeh) Yim                 *   Toronto wins the  \\n*  4B Mathematics (Actuarial Science)    *     (   ?    )    CUP.\\n*  University of Waterloo, Canada.       *  i like \"coca-cola\" idea personally\\n*  E-mail: ayim@descartes.waterloo.edu   *  \\n*****************************************************************************\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hockey_corpus.raw('52555')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub(r'\\W+|_|\\d+',' ',text)\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing our corpus\n",
    "# article = [(data1,type1),(data2,type1)......]\n",
    "hockey_articles = [(preprocessor(hockey_corpus.raw(fileid)),'hockey') for fileid in hockey_corpus.fileids()]\n",
    "baseball_articles = [(preprocessor(baseball_corpus.raw(fileid)),'baseball') for fileid in baseball_corpus.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newsgroup', 'rec', 'sport', 'hockey', 'path', 'cantaloup', 'srv', 'cs', 'cmu', 'edu', 'crabappl', 'srv', 'cs', 'cmu', 'edu', 'fs', 'ece', 'cmu', 'edu', 'europa'] hockey\n"
     ]
    }
   ],
   "source": [
    "print(hockey_articles[0][0][:20],hockey_articles[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging our datasets and building featureset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "documents = hockey_articles + baseball_articles\n",
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['path', 'cantaloup', 'srv', 'cs', 'cmu', 'edu', 'rochest', 'udel', 'gatech', 'howland', 'reston', 'an', 'net', 'noc', 'near', 'net', 'mozz', 'unh', 'edu', 'kepler', 'unh', 'edu', 'mtt', 'from', 'mtt', 'kepler', 'unh', 'edu', 'matthew', 'T', 'thompson', 'newsgroup', 'rec', 'sport', 'basebal', 'subject', 'music', 'censorship', 'survey', 'pleas', 'fill', 'date', 'apr', 'gmt', 'organ', 'univers', 'new', 'hampshir', 'durham', 'NH', 'line', 'messag', 'ID', 'qhph', 'sk', 'mozz', 'unh', 'edu', 'refer', 'C', 'hna', 'F', 'cs', 'uiuc', 'edu', 'nntp', 'post', 'host', 'kepler', 'unh', 'edu', 'hello', 'I', 'paper', 'censorship', 'music', 'I', 'would', 'appreci', 'took', 'time', 'particip', 'survey', 'pleas', 'answer', 'question', 'ask', 'simpli', 'mean', 'room', 'explain', 'answer', 'chose', 'the', 'last', 'question', 'comment', 'question', 'suggest', 'thank', 'advanc', 'pleas', 'E', 'mail', 'address', 'end', 'I', 'male', 'femal', 'II', 'age', 'iii', 'major', 'occup', 'IV', 'type', 'music', 'listen', 'check', 'appli', 'hard', 'rock', 'b', 'metal', 'c', 'altern', 'blue', 'e', 'rap', 'f', 'jazz', 'g', 'soft', 'rock', 'h', 'easi', 'listen', 'countri', 'j', 'classic', 'k', 'hard', 'core', 'l', 'danc', 'new', 'age', 'n', 'other', 'I', 'miss', 'Do', 'think', 'record', 'objection', 'offens', 'lyric', 'label', 'ye', 'whi', 'Do', 'think', 'certain', 'record', 'ban', 'minor', 'year', 'age', 'ye', 'Do', 'think', 'certain', 'record', 'ban', 'period', 'ye', 'whi', 'If', 'ye', 'decid', 'parent', 'b', 'govern', 'c', 'music', 'industri', 'feel', 'free', 'add', 'comment', 'Do', 'think', 'less', 'done', 'control', 'record', 'sale', 'think', 'present', 'label', 'system', 'enough', 'what', 'definit', 'censorship', 'also', 'feel', 'free', 'add', 'comment', 'suggest', 'question', 'explan', 'pleas', 'E', 'mail', 'mtt', 'kepler', 'unh', 'edu', 'hit', 'R', 'repli', 'thank', 'matthew', 'T', 'thompson', 'disclaim', 'respons', 'use', 'paper', 'anoynam', 'sp', 'unless', 'person', 'specifi', 'name', 'use', 'thi', 'sig', 'close', 'repair', 'ution', 'matthew', 'T', 'thompson', 'rrrrrrr', 'pound', 'pound', 'thud', 'ouch', 'duh', 'E', 'mail', 'mtt', 'kepler', 'unh', 'edu', 'shazam', 'unh', 'edu'], 'baseball')\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "(['newsgroup', 'rec', 'sport', 'hockey', 'path', 'cantaloup', 'srv', 'cs', 'cmu', 'edu', 'rochest', 'udel', 'bogu', 'sura', 'net', 'news', 'feed', 'peachnet', 'edu', 'emori', 'wupost', 'crcni', 'unl', 'edu', 'moe', 'ksu', 'ksu', 'edu', 'zaphod', 'mp', 'ohio', 'state', 'edu', 'usc', 'elroy', 'jpl', 'nasa', 'gov', 'nntp', 'server', 'caltech', 'edu', 'draco', 'macsch', 'com', 'odin', 'dev', 'macsch', 'com', 'b', 'hart', 'from', 'b', 'hart', 'odin', 'dev', 'macsch', 'com', 'bill', 'hart', 'subject', 'Re', 'If', 'oiler', 'go', 'hamilton', 'messag', 'ID', 'apr', 'draco', 'macsch', 'com', 'line', 'sender', 'b', 'hart', 'odin', 'macsch', 'com', 'bill', 'hart', 'repli', 'To', 'b', 'hart', 'macsch', 'com', 'organ', 'macneal', 'schwendler', 'corpor', 'refer', 'apr', 'spang', 'camosun', 'BC', 'CA', 'date', 'mon', 'apr', 'gmt', 'In', 'articl', 'apr', 'spang', 'camosun', 'BC', 'CA', 'ua', 'freenet', 'victoria', 'BC', 'CA', 'tom', 'moffat', 'write', 'If', 'oiler', 'move', 'hamilton', 'divis', 'play', 'tom', 'moffat', 'victoria', 'B', 'C', 'canada', 'As', 'guess', 'hamilton', 'would', 'put', 'midwest', 'either', 'winnipeg', 'dalla', 'move', 'pacif', 'bill', 'b', 'hart', 'macsch', 'com'], 'hockey')\n"
     ]
    }
   ],
   "source": [
    "print(documents[10])\n",
    "print(\"__________________________________________________________________________________________________\")\n",
    "print(\"\")\n",
    "print(documents[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomizing\n",
    "import random\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering all words together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list()\n",
    "for tuple_ in documents:\n",
    "    for word in tuple_[0]:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edu', 1571),\n",
       " ('I', 791),\n",
       " ('apr', 506),\n",
       " ('cmu', 423),\n",
       " ('cs', 416),\n",
       " ('com', 401),\n",
       " ('news', 299),\n",
       " ('net', 260),\n",
       " ('srv', 249),\n",
       " ('sport', 248)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_frequency = nltk.FreqDist(all_words)\n",
    "all_words_frequency.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5863, 42598)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_words)),len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "print(all_words_frequency['game'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most common words in both the data sets combined are \n",
    "`\n",
    "('edu', 1571),\n",
    " ('I', 791),\n",
    " ('apr', 506),\n",
    " ('cmu', 423),\n",
    " ('cs', 416),\n",
    " ('com', 401),\n",
    " ('news', 299),\n",
    " ('net', 260),\n",
    " ('srv', 249),\n",
    " ('sport', 248)\n",
    " `.\n",
    " We can also notice that there are many words that are repeated in both document sets. Length of all_words list is 42598 while length of set(all_words) is 5863. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building feature set:\n",
    "In a feature set we assign `True` or `False` for presence or absence of word from all_words set, to documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = all_words\n",
    "#defining function to map our NLTK friendly dataset\n",
    "def find_dataset(wordset):\n",
    "    words = set(wordset)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = w in words\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = [(find_dataset(wordset),cat) for (wordset,cat) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_set[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our feature set is ready with bool values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test set\n",
    "train = feature_set[:160]\n",
    "test = feature_set[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x16f50f61780>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Naive Bayes Model\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99375"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier,train)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  hockey = False          baseba : hockey =     53.7 : 1.0\n",
      "                 basebal = False          hockey : baseba =     49.7 : 1.0\n",
      "                    goal = True           hockey : baseba =     13.7 : 1.0\n",
      "                 basebal = True           baseba : hockey =     12.2 : 1.0\n",
      "                    note = True           baseba : hockey =      7.7 : 1.0\n",
      "                    base = True           baseba : hockey =      7.7 : 1.0\n",
      "                  cornel = True           baseba : hockey =      7.0 : 1.0\n",
      "                     cup = True           hockey : baseba =      7.0 : 1.0\n",
      "                  philli = True           baseba : hockey =      7.0 : 1.0\n",
      "                     ice = True           hockey : baseba =      7.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "results = [classifier.classify(x[0]) for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "svc_classifier = SklearnClassifier(SVC(kernel='rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classifier.train(train)\n",
    "accuracy_train = nltk.classify.accuracy(svc_classifier,train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test = nltk.classify.accuracy(svc_classifier,test)\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99375\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "svc_classifier = SklearnClassifier(SVC(kernel='rbf',C=8))\n",
    "svc_classifier.train(train)\n",
    "accuracy_train = nltk.classify.accuracy(svc_classifier,train)\n",
    "print(accuracy_train)\n",
    "accuracy_test = nltk.classify.accuracy(svc_classifier,test)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99375\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "RFclassifier = SklearnClassifier(RandomForestClassifier(n_estimators=50))\n",
    "RFclassifier.train(train)\n",
    "accuracy_train = nltk.classify.accuracy(RFclassifier,train)\n",
    "print(accuracy_train)\n",
    "accuracy_test = nltk.classify.accuracy(RFclassifier,test)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "We have used here three categorization algorithms namely `Naive Bayes`, `Support Vector Machines` and `Random Forest`. We were already able to achieve approx 100% accuracy in `Naive Bayes` . For the remaining two algorithms we need to tweak the hyper parameters and we could achieve 100% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
